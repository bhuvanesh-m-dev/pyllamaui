# PyLlamaUI 🐍🦙  
*A Python-based offline GUI for running AI models with Ollama*

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Ollama](https://img.shields.io/badge/Powered%20by-Ollama-yellow)
![Open Source](https://img.shields.io/badge/Open--Source-Yes-brightgreen)

---

## 🌟 About

**PyLlamaUI** is an open-source offline desktop application built with Python that lets you run and chat with large language models (LLMs) using [Ollama](https://ollama.com).

No cloud. No tracking. Just pure local AI — fast and private.

---

## 🚀 Features

- 🖥️ Simple, clean GUI for chatting with LLMs
- 🔌 Interacts with local Ollama server via REST API
- 🔄 Load and switch between models (e.g., LLaMA 3, Mistral, etc.)
- 💾 Save prompt history locally
- ⚙️ Customizable settings: max tokens, temperature, system prompt
- 🌓 Light/dark mode support *(optional)*

---

## 🛠️ Tech Stack

- **Python 3.10+**
- `customtkinter` (or `tkinter`) for GUI  
- `requests` for Ollama API calls  
- **Ollama** (installed locally and running in background)

---

## 📸 Screenshots

> Coming soon...

---

## 📦 Installation

### 1. Prerequisites
- 🐍 Python 3.10+
- 🦙 [Ollama](https://ollama.com/download) installed and running locally  
```bash
ollama run llama3
