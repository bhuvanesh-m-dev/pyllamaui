# PyLlamaUI ğŸï¿½ï¿½  
<p align="center">
  <img src="document/logo.png" alt="PyLlamaUI Logo" width="200">
</p>  

*A Python-based offline GUI for running AI models with Ollama*

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Ollama](https://img.shields.io/badge/Powered%20by-Ollama-yellow)
![Open Source](https://img.shields.io/badge/Open--Source-Yes-brightgreen)

---

## ğŸŒŸ About

**PyLlamaUI** is an open-source offline desktop application built with Python that lets you run and chat with large language models (LLMs) using [Ollama](https://ollama.com).

> ğŸ§  No cloud. No tracking. Just pure local AI â€” fast, secure, and private.

---

## ğŸš€ Features

* ğŸ–¥ï¸ Simple, clean GUI for chatting with LLMs
* ğŸ”Œ Interacts with local Ollama server via REST API
* ğŸ”„ Load and switch between models (e.g., LLaMA 3, Mistral)
* ğŸ“€ Save prompt history locally
* âš™ï¸ Customizable settings: max tokens, temperature, system prompt
* ğŸŒ— Light/dark mode support *(optional)*

---

## ğŸ› ï¸ Tech Stack

* **Python 3.10+**
* [`customtkinter`](https://github.com/TomSchimansky/CustomTkinter) for GUI
* `requests` for API communication
* [Ollama](https://ollama.com) (installed and running locally)

---

## ğŸ“¦ Windows `.exe` Version

We offer a pre-built `.exe` file for Windows users:

ğŸ‘‰ **[Download latest `.exe`](https://github.com/YOUR_USERNAME/YOUR_REPO/releases/latest)** from the Releases section.

> âš ï¸ Make sure [Ollama](https://ollama.com/download) is installed and running on your system before launching the app.

---

## ğŸ§ Linux & macOS

Use the Python source directly or a `.deb` (coming soon):

```bash
git clone https://github.com/YOUR_USERNAME/pyllamaui.git
cd pyllamaui
pip install -r requirements.txt
python main.py
```

---

## ğŸ“¸ Screenshots

> Coming soon...

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ¤ Contributing

Feel free to fork, raise issues, or send PRs! Contributions are always welcome.
