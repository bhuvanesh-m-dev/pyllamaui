# PyLlamaUI ğŸğŸ¦™  
*A Python-based offline GUI for running AI models with Ollama*

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Ollama](https://img.shields.io/badge/Powered%20by-Ollama-yellow)
![Open Source](https://img.shields.io/badge/Open--Source-Yes-brightgreen)

---

## ğŸŒŸ About

**PyLlamaUI** is an open-source offline desktop application built with Python that lets you run and chat with large language models (LLMs) using [Ollama](https://ollama.com).

No cloud. No tracking. Just pure local AI â€” fast and private.

---

## ğŸš€ Features

- ğŸ–¥ï¸ Simple, clean GUI for chatting with LLMs
- ğŸ”Œ Interacts with local Ollama server via REST API
- ğŸ”„ Load and switch between models (e.g., LLaMA 3, Mistral, etc.)
- ğŸ’¾ Save prompt history locally
- âš™ï¸ Customizable settings: max tokens, temperature, system prompt
- ğŸŒ“ Light/dark mode support *(optional)*

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- `customtkinter` (or `tkinter`) for GUI  
- `requests` for Ollama API calls  
- **Ollama** (installed locally and running in background)

---

## ğŸ“¸ Screenshots

> Coming soon...

---

## ğŸ“¦ Installation

### 1. Prerequisites
- ğŸ Python 3.10+
- ğŸ¦™ [Ollama](https://ollama.com/download) installed and running locally  
```bash
ollama run llama3
