# PyLlamaUI ğŸğŸ¦™  
*A Python-based offline GUI for running AI models with Ollama*

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Ollama](https://img.shields.io/badge/Powered%20by-Ollama-yellow)
![Open Source](https://img.shields.io/badge/Open--Source-Yes-brightgreen)

---

## ğŸŒŸ About

**PyLlamaUI** is an open-source offline desktop application built with Python that lets you run and chat with large language models (LLMs) using [Ollama](https://ollama.com).

No cloud. No tracking. Just pure local AI â€” fast and private.

---

## ğŸš€ Features

- ğŸ–¥ï¸ Simple, clean GUI for chatting with LLMs
- ğŸ”Œ Interacts with local Ollama server via REST API
- ğŸ”„ Load and switch between models (e.g., LLaMA 3, Mistral, etc.)
- ğŸ’¾ Save prompt history locally
- âš™ï¸ Customizable settings: max tokens, temperature, system prompt
- ğŸŒ“ Light/dark mode support *(optional)*

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- `customtkinter` (or `tkinter`) for GUI  
- `requests` for Ollama API calls  
- **Ollama** (installed locally and running in background)

---

## ğŸ“¸ Screenshots

> Coming soon...

---
<p align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%" alt="Header Banner">
</p> 
 <h3 align="center">
    ğŸŒŒ You are my &nbsp;
    <a href="https://github.com/bhuvanesh-m-dev">
    <img src="https://count.getloli.com/@bhuvanesh-m-dev?name=bhuvanesh-m-dev&theme=ai-1&padding=13&offset=0&align=top&scale=1&pixelated=1&darkmode=auto" alt="bhuvanesh-m-dev" />
    </a>
    &nbsp; visitor. Welcome to my orbit.
</h3>
<p align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%" alt="Header Banner">
</p>

   
## ğŸ“¦ Installation

### 1. Prerequisites
- ğŸ Python 3.10+
- ğŸ¦™ [Ollama](https://ollama.com/download) installed and running locally  
```bash
ollama run llama3 
